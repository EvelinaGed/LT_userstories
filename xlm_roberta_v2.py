# -*- coding: utf-8 -*-
"""XLM-RoBERTa_v2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bqvOcuaq6H90Jf1A4_PtWZC1wMjs56-a
"""

import pandas as pd
import torch
import numpy as np
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from torch.utils.data import Dataset, DataLoader
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from torch.optim import AdamW
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

# 1. Duomenų nuskaitymas ir paruošimas
df_train = pd.read_csv('https://raw.githubusercontent.com/EvelinaGed/LT_userstories/refs/heads/main/Training_user_stories_LT_v4.csv')
df_test = pd.read_csv('https://raw.githubusercontent.com/EvelinaGed/LT_userstories/refs/heads/main/test_set_LT_v4.csv')

df_train.columns = df_train.columns.str.strip()
df_test.columns = df_test.columns.str.strip()

for df in [df_train, df_test]:
    for col in ["KR1", "KR2", "KR3"]:
        if df[col].dtype == object:
            df[col] = df[col].str.strip().str.lower().map({"yes": 1, "no": 0})
        df[col] = pd.to_numeric(df[col], errors='coerce')

df_train.dropna(subset=["KR1", "KR2", "KR3"], inplace=True)
df_test.dropna(subset=["KR1", "KR2", "KR3"], inplace=True)

# 2. Modelis ir tokenizeris (XLM-R)
model_name = "xlm-roberta-base"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)

# 3. Įranga
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# 4. Dataset klasė
class UserStoriesDataset(Dataset):
    def __init__(self, texts, labels, tokenizer):
        self.encodings = tokenizer(texts, truncation=True, padding=True, return_tensors="pt")
        self.labels = labels

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        item = {key: val[idx] for key, val in self.encodings.items()}
        label = self.labels[idx]
        label = [0 if pd.isna(val) else int(val) for val in label]
        item['labels'] = torch.tensor(label, dtype=torch.float)
        return item

# 5. Dataset ir Dataloader
train_dataset = UserStoriesDataset(df_train['User stories'].tolist(), df_train[["KR1", "KR2", "KR3"]].values.tolist(), tokenizer)
test_dataset = UserStoriesDataset(df_test['User stories'].tolist(), df_test[["KR1", "KR2", "KR3"]].values.tolist(), tokenizer)

train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=16)

# 6. Optimizer ir loss
optimizer = AdamW(model.parameters(), lr=5e-5)
loss_fn = torch.nn.BCEWithLogitsLoss()

# 7. Treniruotė
model.train()
epochs = 3

for epoch in range(epochs):
    total_loss = 0
    for batch in train_loader:
        inputs = {key: val.to(device) for key, val in batch.items() if key != 'labels'}
        labels = batch['labels'].to(device)

        optimizer.zero_grad()
        outputs = model(**inputs)
        loss = loss_fn(outputs.logits, labels)
        loss.backward()
        optimizer.step()

        total_loss += loss.item()

    print(f"Epoch {epoch + 1}, Loss: {total_loss:.4f}")

# 8. Testavimas
model.eval()
all_preds = []
all_labels = []

with torch.no_grad():
    for batch in test_loader:
        inputs = {key: val.to(device) for key, val in batch.items() if key != 'labels'}
        labels = batch['labels'].to(device)
        outputs = model(**inputs)
        probs = torch.sigmoid(outputs.logits)
        preds = (probs > 0.5).int()
        all_preds.extend(preds.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

all_labels = np.array(all_labels)
all_preds = np.array(all_preds)

# 9. Metrikos
metrics = ["Accuracy", "Precision", "Recall", "F1"]
label_names = ["Atomiškumas", "Pilnumas", "Dviprasmiškumas"]

for i, label in enumerate(label_names):
    acc = accuracy_score(all_labels[:, i], all_preds[:, i])
    prec = precision_score(all_labels[:, i], all_preds[:, i], zero_division=0)
    rec = recall_score(all_labels[:, i], all_preds[:, i], zero_division=0)
    f1 = f1_score(all_labels[:, i], all_preds[:, i], zero_division=0)
    print(f"\n{label}:")
    print(f"  Accuracy:  {acc:.2f}")
    print(f"  Precision: {prec:.2f}")
    print(f"  Recall:    {rec:.2f}")
    print(f"  F1 Score:  {f1:.2f}")

# 10. Confusion matrices
for i, label in enumerate(label_names):
    cm = confusion_matrix(all_labels[:, i], all_preds[:, i])
    plt.figure(figsize=(4, 3))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
    plt.title(f"{label} Confusion Matrix")
    plt.xlabel('Prognozuota')
    plt.ylabel('Tikroji')
    plt.tight_layout()
    plt.show()