# -*- coding: utf-8 -*-
"""LitLatBERT_v2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZagmO5nrSfLMnu_7VLtgDuI4jB6OT-p0
"""

from huggingface_hub import login
login(token="X")
import pandas as pd
import torch
import numpy as np
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from torch.utils.data import Dataset, DataLoader
from sklearn.metrics import accuracy_score
from torch.optim import AdamW
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix


# Nuskaitome duomenis
df_train = pd.read_csv('https://raw.githubusercontent.com/EvelinaGed/LT_userstories/refs/heads/main/Training_user_stories_LT_v4.csv')
df_test = pd.read_csv('https://raw.githubusercontent.com/EvelinaGed/LT_userstories/refs/heads/main/test_set_LT_v4.csv')

# Pašalinti galimus tarpus stulpeliuose
df_train.columns = df_train.columns.str.strip()
df_test.columns = df_test.columns.str.strip()

# Patikriname, kokie stulpeliai yra DataFrame
print("Train DataFrame stulpeliai:", df_train.columns)
print("Test DataFrame stulpeliai:", df_test.columns)

# KR1 paliekame nepaliestą, nes jame jau yra 0/1, konvertuojame tik KR2 ir KR3 jeigu reikia
if df_train["KR2"].dtype == object:
    df_train["KR2"] = df_train["KR2"].map({"yes": 1, "no": 0})
if df_train["KR3"].dtype == object:
    df_train["KR3"] = df_train["KR3"].map({"yes": 1, "no": 0})

if df_test["KR2"].dtype == object:
    df_test["KR2"] = df_test["KR2"].map({"yes": 1, "no": 0})
if df_test["KR3"].dtype == object:
    df_test["KR3"] = df_test["KR3"].map({"yes": 1, "no": 0})

# LitLat BERT modelio ir tokenizer įkėlimas
model_name = "EMBEDDIA/litlat-bert"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)

# Įranga
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# Dataset klasė
class UserStoriesDataset(Dataset):
    def __init__(self, texts, labels, tokenizer):
        self.encodings = tokenizer(texts, truncation=True, padding=True, return_tensors="pt")
        self.labels = labels

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        item = {key: val[idx] for key, val in self.encodings.items()}
        label = self.labels[idx]
        label = [0 if pd.isna(val) else int(val) for val in label]
        item['labels'] = torch.tensor(label, dtype=torch.float)
        return item

# Paruošiame duomenis
train_dataset = UserStoriesDataset(
    texts=df_train['User stories'].tolist(),
    labels=df_train[["KR1", "KR2", "KR3"]].values.tolist(),
    tokenizer=tokenizer
)

test_dataset = UserStoriesDataset(
    texts=df_test['User stories'].tolist(),
    labels=df_test[["KR1", "KR2", "KR3"]].values.tolist(),
    tokenizer=tokenizer
)

train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=8)

# Optimizatorius ir nuostolių funkcija
optimizer = AdamW(model.parameters(), lr=5e-5)
loss_fn = torch.nn.BCEWithLogitsLoss()

# Modelio treniravimas
model.train()
epochs = 3

for epoch in range(epochs):
    total_loss = 0
    for batch in train_loader:
        inputs = {key: val.to(device) for key, val in batch.items() if key != 'labels'}
        labels = batch['labels'].to(device)

        optimizer.zero_grad()
        outputs = model(**inputs)

        loss = loss_fn(outputs.logits, labels)
        loss.backward()
        optimizer.step()

        total_loss += loss.item()

    print(f"Epoch {epoch + 1}, Loss: {total_loss:.4f}")


# Modelio testavimas
model.eval()
all_preds = []
all_labels = []

with torch.no_grad():
    for batch in test_loader:
        inputs = {key: val.to(device) for key, val in batch.items() if key != 'labels'}
        labels = batch['labels'].to(device)

        outputs = model(**inputs)
        probs = torch.sigmoid(outputs.logits)
        preds = (probs > 0.5).int()

        all_preds.extend(preds.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

all_labels = np.array(all_labels)
all_preds = np.array(all_preds)

# Tikslumo skaičiavimas
accuracy = accuracy_score(all_labels, all_preds)
print(f"Test accuracy: {accuracy:.2f}")

accuracy_atomic = accuracy_score(all_labels[:, 0], all_preds[:, 0])
accuracy_completeness = accuracy_score(all_labels[:, 1], all_preds[:, 1])
accuracy_ambiguity = accuracy_score(all_labels[:, 2], all_preds[:, 2])

print(f"Atomiškumo tikslumas: {accuracy_atomic:.2f}")
print(f"Pilnumo tikslumas: {accuracy_completeness:.2f}")
print(f"Dviprasmiškumo tikslumas: {accuracy_ambiguity:.2f}")

# F1, Precision ir Recall kiekvienam kriterijui
from sklearn.metrics import precision_score, recall_score, f1_score

metrics = ["Atomiškumas", "Pilnumas", "Dviprasmiškumas"]
for i in range(3):
    precision = precision_score(all_labels[:, i], all_preds[:, i], zero_division=0)
    recall = recall_score(all_labels[:, i], all_preds[:, i], zero_division=0)
    f1 = f1_score(all_labels[:, i], all_preds[:, i], zero_division=0)
    print(f"{metrics[i]} – Precision: {precision:.2f}, Recall: {recall:.2f}, F1: {f1:.2f}")

# Confusion Matrix atvaizdavimas
def plot_confusion_matrix(y_true, y_pred, title):
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(4, 3))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
    plt.title(title)
    plt.xlabel('Prognozuota')
    plt.ylabel('Tikroji')
    plt.show()

plot_confusion_matrix(all_labels[:, 0], all_preds[:, 0], "Atomiškumo Confusion Matrix")
plot_confusion_matrix(all_labels[:, 1], all_preds[:, 1], "Pilnumo Confusion Matrix")
plot_confusion_matrix(all_labels[:, 2], all_preds[:, 2], "Dviprasmiškumo Confusion Matrix")